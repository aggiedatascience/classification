{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Checkpoint #1: *Open the Notebook and Load the Data***\n"
      ],
      "metadata": {
        "id": "Qdi7b0NNQtGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go to https://docs.google.com/presentation/d/1z9HhCQ2ldON_tb9JLuJlb_bH9cghNhHwXCE-nqxbaUI/edit?usp=sharing for help on running the notebook in Colab."
      ],
      "metadata": {
        "id": "su2XI6qxZuRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtN-dQE9MilS",
        "outputId": "67193655-493b-416f-ea9e-a5960b9d3311"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cd drive/MyDrive/Regression\\ Workshop\n",
        "%cd drive/Shareddrives/Aggie\\ Data\\ Science\\ Club/Workshops/SP24\\ Classification"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md-tXurDMzsx",
        "outputId": "414203bb-c998-452c-e80e-b50caad7991d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shareddrives/Aggie Data Science Club/Workshops/SP24 Classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "GZPFKz5hYj0-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IRtodPr-MZ7N"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('2016_Citizen_Survey_Master_Dataset_20240218.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Checkpoint #2: *Prepare the Data with Imputation and Encoding***\n"
      ],
      "metadata": {
        "id": "N_iGJNc2RbRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nulls = df.isnull().sum().sum()\n",
        "print(f\"Total number of nulls in dataset (original): {nulls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj2wqXvkYqIT",
        "outputId": "a3f42ae9-bc29-4e36-b2de-8b793d9e7969"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of nulls in dataset (original): 125767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.tutorialspoint.com/how-to-handle-missing-values-of-categorical-variables-in-python#:~:text=in%20the%20section.-,Fill%20the%20missing%20values%20with%20the%20computed%20mode%20using%20the,method_name%20parameter%20as%20'mode'.\n",
        "\n"
      ],
      "metadata": {
        "id": "xPcW83nahS1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Evaluation:\n",
        "# Shape\n",
        "# remove null values\n",
        "# convert categorical values, etc.\n",
        "\n",
        "# Checkpoint 1: clean / drop null values\n",
        "# rename values and columns (mainly area column )\n",
        "# Handling null values\n",
        "\n",
        "df.drop(columns=[\"Information preference about city government activities - Other\"], inplace=True, errors=\"ignore\")\n",
        "\n",
        "for column in df.columns:\n",
        "  num_nulls_in_column = df[column].isnull().sum()\n",
        "  if num_nulls_in_column != 0:\n",
        "    column_dtype = df[column].dtype\n",
        "    if column_dtype == 'object':  # Categorical columns\n",
        "      mode = df[column].mode()[0]\n",
        "      df[column] = df[column].fillna(mode)\n",
        "    elif column_dtype in ('float64', 'int64'):  # Numerical columns\n",
        "      mean = df[column].mean()\n",
        "      df[column] = df[column].fillna(mean)\n",
        "\n",
        "new_nulls = df.isnull().sum().sum()\n",
        "print(f\"Total number of nulls in dataset (after imputation): {new_nulls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIKR5eCIMg9y",
        "outputId": "eba7fd43-bbb2-4365-84d9-6979f05e956d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of nulls in dataset (after imputation): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(columns={'Area of College Station': 'area'}, inplace=True)\n",
        "\n",
        "y = df[\"area\"]"
      ],
      "metadata": {
        "id": "8LWImWY7lFZ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_categorical_before = df.select_dtypes(include=['object']).shape[1]\n",
        "print(f\"Number of categorical variables before encoding: {num_categorical_before}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_zPUK4ZY4P2",
        "outputId": "737611b2-b035-453f-890f-de2cfeba58ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categorical variables before encoding: 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to determine the encoding technique for a column based on the number of unique values\n",
        "# Dont worry abt this but if unique values > 10, then were gonna use a frequency encoding stategy good for high-cardinality categorical variables\n",
        "def determine_encoding(column):\n",
        "    unique_values = column.nunique()\n",
        "    # If the number of unique values is too high, return None to avoid encoding\n",
        "    if unique_values > 10:\n",
        "        return None\n",
        "    elif unique_values == 2:  # for binary columns\n",
        "        return \"Label\"\n",
        "    else:\n",
        "        return \"OneHot\"\n",
        "\n",
        "X = df.drop(columns=[\"area\"], inplace=False, errors=\"ignore\")\n",
        "\n",
        "one_hot_columns = []\n",
        "drop_columns = []\n",
        "\n",
        "for col in X.columns:\n",
        "  if X[col].dtype == 'object':  # Check if the column is categorical\n",
        "    encoding_type = determine_encoding(X[col])\n",
        "    if encoding_type == \"Label\":\n",
        "      le = LabelEncoder()\n",
        "      X[col] = le.fit_transform(X[col])\n",
        "    elif encoding_type == \"OneHot\":\n",
        "      one_hot_columns.append(col)\n",
        "    else:\n",
        "      drop_columns.append(col)\n",
        "\n",
        "X = pd.get_dummies(X, columns=one_hot_columns)\n",
        "\n",
        "encoded_shape = X.shape\n",
        "print(f\"Shape of the Encoded DataFrame: {encoded_shape}\")\n",
        "num_categorical_after = X.select_dtypes(include=['object']).shape[1]\n",
        "print(f\"Number of categorical variables after encoding: {num_categorical_after}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrcQVe_LYmkf",
        "outputId": "5bdedf4b-020c-4a58-cfac-7f814bf455b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the Encoded DataFrame: (2015, 518)\n",
            "Number of categorical variables after encoding: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#there are still some categorical variables left, specifically high cardinality variables\n",
        "\n",
        "remaining_categorical_vars = X.select_dtypes(include=['object'])\n",
        "columns_with_many_categories = remaining_categorical_vars.apply(lambda col: col.nunique() > 10)\n",
        "\n",
        "print(columns_with_many_categories)\n",
        "\n",
        "# trying out frequency encoding:\n",
        "columns_to_encode = columns_with_many_categories[columns_with_many_categories].index.tolist()\n",
        "print(columns_to_encode)\n",
        "\n",
        "for col in columns_to_encode:\n",
        "    frequency = X[col].value_counts(normalize=True)  # frequency of each category\n",
        "    X[col] = X[col].map(frequency)\n",
        "\n",
        "num_categorical_after = X.select_dtypes(include=['object']).shape[1]\n",
        "print(f\"Number of categorical variables after encoding: {num_categorical_after}\") #now there's 0 categorical variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtuwgBz8FZfg",
        "outputId": "9ccc0baa-51bb-4f7a-bd54-81054f5ddc02"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dwelling type Other                                                                         True\n",
            "Additional comments about specific city services or departments                             True\n",
            "What do you value MOST about living in College Station?                                     True\n",
            "If you could change ONE THING about College Station, what would it be                       True\n",
            "What would you say should be College Station's highest priority                             True\n",
            "What types of retail and commercial development would you like to see in College Station    True\n",
            "How could the city's customer service be improved                                           True\n",
            "Information preference Other                                                                True\n",
            "How could the city improve its public communication efforts?                                True\n",
            "Additional comments about College Station's municipal buildings and facilities              True\n",
            "dtype: bool\n",
            "['Dwelling type Other', 'Additional comments about specific city services or departments', 'What do you value MOST about living in College Station?', 'If you could change ONE THING about College Station, what would it be', \"What would you say should be College Station's highest priority\", 'What types of retail and commercial development would you like to see in College Station', \"How could the city's customer service be improved\", 'Information preference Other', 'How could the city improve its public communication efforts?', \"Additional comments about College Station's municipal buildings and facilities\"]\n",
            "Number of categorical variables after encoding: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Checkpoint #3: *Run the Base Models***\n"
      ],
      "metadata": {
        "id": "GPXj3PkoRpuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Checking the shapes of the resulting splits\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUUFNj696qca",
        "outputId": "facf1e1d-d68b-4667-e7cd-004f6de81911"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1612, 518), (403, 518), (1612,), (403,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_predict_eval(model):\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  model_pred = model.predict(X_test)\n",
        "\n",
        "  model_report = classification_report(model_pred, y_test)\n",
        "  model_matrix = confusion_matrix(model_pred, y_test)\n",
        "\n",
        "  return model_report, model_matrix"
      ],
      "metadata": {
        "id": "vF6M_80bR7vl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()   #Penalty/regularization is optional\n",
        "\n",
        "lr_report, lr_matrix = fit_predict_eval(lr)\n",
        "\n",
        "print(lr_report)\n",
        "print(lr_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsBF_RoXSJqC",
        "outputId": "37cc409d-48f1-414a-e2e9-d1661ea6cc3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                           precision    recall  f1-score   support\n",
            "\n",
            "Area A - North or Rock Prairie Rd. and West of Texas Ave.       0.80      0.88      0.84       116\n",
            "    Area B - North of Bird Pond Rd and East of Texas Ave.       0.78      0.93      0.84        67\n",
            "    Area C - South of Rock Prairie Rd. and West of Hwy. 6       0.96      0.89      0.93       148\n",
            "       Area D - South of Bird Pond Rd. and East of Hwy. 6       0.85      0.69      0.76        72\n",
            "\n",
            "                                                 accuracy                           0.86       403\n",
            "                                                macro avg       0.85      0.85      0.84       403\n",
            "                                             weighted avg       0.87      0.86      0.86       403\n",
            "\n",
            "[[102   6   4   4]\n",
            " [  2  62   1   2]\n",
            " [  5   8 132   3]\n",
            " [ 18   4   0  50]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier()   #Penalty/regularization is optional\n",
        "\n",
        "knn_report, knn_matrix = fit_predict_eval(knn)\n",
        "\n",
        "print(knn_report)\n",
        "print(knn_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1bjL9mq47H6",
        "outputId": "804740e7-48df-478d-8a29-a9590de8739b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                           precision    recall  f1-score   support\n",
            "\n",
            "Area A - North or Rock Prairie Rd. and West of Texas Ave.       0.45      0.39      0.42       146\n",
            "    Area B - North of Bird Pond Rd and East of Texas Ave.       0.24      0.24      0.24        79\n",
            "    Area C - South of Rock Prairie Rd. and West of Hwy. 6       0.45      0.43      0.44       141\n",
            "       Area D - South of Bird Pond Rd. and East of Hwy. 6       0.32      0.51      0.40        37\n",
            "\n",
            "                                                 accuracy                           0.39       403\n",
            "                                                macro avg       0.36      0.39      0.37       403\n",
            "                                             weighted avg       0.39      0.39      0.39       403\n",
            "\n",
            "[[57 35 43 11]\n",
            " [22 19 25 13]\n",
            " [41 23 61 16]\n",
            " [ 7  3  8 19]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = RandomForestClassifier()   #Penalty/regularization is optional\n",
        "\n",
        "rfc_report, rfc_matrix = fit_predict_eval(rfc)\n",
        "\n",
        "print(rfc_report)\n",
        "print(rfc_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a0nDpQsBjkJ",
        "outputId": "1738adfc-bbb6-4c50-9d78-ef80421dac93"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                           precision    recall  f1-score   support\n",
            "\n",
            "Area A - North or Rock Prairie Rd. and West of Texas Ave.       1.00      0.99      1.00       128\n",
            "    Area B - North of Bird Pond Rd and East of Texas Ave.       1.00      1.00      1.00        80\n",
            "    Area C - South of Rock Prairie Rd. and West of Hwy. 6       1.00      1.00      1.00       137\n",
            "       Area D - South of Bird Pond Rd. and East of Hwy. 6       0.98      1.00      0.99        58\n",
            "\n",
            "                                                 accuracy                           1.00       403\n",
            "                                                macro avg       1.00      1.00      1.00       403\n",
            "                                             weighted avg       1.00      1.00      1.00       403\n",
            "\n",
            "[[127   0   0   1]\n",
            " [  0  80   0   0]\n",
            " [  0   0 137   0]\n",
            " [  0   0   0  58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC()   # Kernel is optional\n",
        "\n",
        "svm_report, svm_matrix = fit_predict_eval(svm)\n",
        "\n",
        "print(svm_report)\n",
        "print(svm_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFiSMg7pL3dT",
        "outputId": "97acb59c-06c8-4ae5-b4fe-34db07d508a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                           precision    recall  f1-score   support\n",
            "\n",
            "Area A - North or Rock Prairie Rd. and West of Texas Ave.       0.15      0.28      0.20        67\n",
            "    Area B - North of Bird Pond Rd and East of Texas Ave.       0.00      0.00      0.00         0\n",
            "    Area C - South of Rock Prairie Rd. and West of Hwy. 6       0.85      0.35      0.49       336\n",
            "       Area D - South of Bird Pond Rd. and East of Hwy. 6       0.00      0.00      0.00         0\n",
            "\n",
            "                                                 accuracy                           0.33       403\n",
            "                                                macro avg       0.25      0.16      0.17       403\n",
            "                                             weighted avg       0.73      0.33      0.44       403\n",
            "\n",
            "[[ 19  21  21   6]\n",
            " [  0   0   0   0]\n",
            " [108  59 116  53]\n",
            " [  0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Checkpoint #4: *Fine-Tune the Hyperparameters***\n"
      ],
      "metadata": {
        "id": "IxOQyC36UMTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try different models with different hyperparameters\n",
        "# you have to improve SVM or KNN"
      ],
      "metadata": {
        "id": "zYxOAMSNOdf_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4UqEnXtVxLo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}